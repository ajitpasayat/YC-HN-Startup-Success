{
 "metadata": {
  "name": "",
  "signature": "sha256:43a4cd8350fb186ed5f6a18d70d47d31115419d9e09150be1d863b556b050d05"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import feature_extraction\n",
      "\n",
      "# Borrowed from: http://nbviewer.ipython.org/github/gmonce/scikit-learn-book/tree/master/ (Chapter 4)\n",
      "def one_hot_dataframe(data, cols, replace=False):\n",
      "    \"\"\" Takes a dataframe and a list of columns that need to be encoded.\n",
      "    Returns a 3-tuple comprising the data, the vectorized data,\n",
      "    and the fitted vectorizor.\n",
      "    Modified from https://gist.github.com/kljensen/5452382\n",
      "    \"\"\"\n",
      "    vec = feature_extraction.DictVectorizer()\n",
      "    mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
      "\n",
      "    vecData = pd.DataFrame(vec.fit_transform(data[cols].to_dict(outtype='records')).toarray())\n",
      "    vecData.columns = vec.get_feature_names()\n",
      "    vecData.index = data.index\n",
      "    if replace is True:\n",
      "        data = data.drop(cols, axis=1)\n",
      "        data = data.join(vecData)\n",
      "    return (data, vecData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load HackerNews data.\n",
      "hacerknewsdata = pd.DataFrame()\n",
      "hackernewsdata = pd.read_csv('HNTitleCommentsSentimentData.csv')\n",
      "hackernewsdata = hackernewsdata.drop(['Unnamed: 0'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load YC startups data.\n",
      "cleanstartups = pd.DataFrame()\n",
      "cleanstartups = pd.read_csv('CleanStartups.csv')\n",
      "cleanstartups = cleanstartups.drop(['Unnamed: 0'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Merge the cleaned-up YC startup data with Hacker News data.\n",
      "fullset = pd.merge(hackernewsdata, cleanstartups, on='Company', how='inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Going to convert those that have exited YC as remaining in operation.\n",
      "# I want to keep the perdiction simple: in operation or dead.\n",
      "# I will think of ways to incorporate startups that have exited as a classifer after my demo.\n",
      "fullset.Fate[fullset.Fate != 'Dead'] = 'Operating'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To create training set, first separate startups that are not operating versus those that remain in operation.\n",
      "# Because there aren't as many dead startups, I will only use an equal amount of active startups (chosen by random). \n",
      "deadset = fullset[fullset.Fate == 'Dead']\n",
      "operatingset = fullset[fullset.Fate == 'Operating']\n",
      "rows = np.random.choice(operatingset.index.values, len(deadset))\n",
      "operatingset = operatingset.ix[rows]\n",
      "\n",
      "# Now merge together the dead and operating startups -- this will be the training set for now.\n",
      "trainingset = deadset.append(operatingset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Truncating full set to exclude features that aren't going to be in the decision tree.\n",
      "trainingset = trainingset.drop(['Company','Title','TopComment','TopCommentPoints', 'Fate','Description','Logo',\n",
      "                    'SeedDBMattermarkProfile', 'CrunchBaseAngelListProfile', 'Website',\n",
      "                    'YCYear', 'YCSession'], 1)\n",
      "\n",
      "# Also have to deal with missing values and data types.\n",
      "trainingset[['Sentiment','TotalFunds']] = trainingset[['Sentiment','TotalFunds']].fillna(0.0).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testset = pd.DataFrame(fullset.Fate[trainingset.index])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transforming lists of feature-value mappings to vectors.\n",
      "# This also transforms and encodes categorical integer features using a variation of one-hot scheme.\n",
      "trainingset, trainingset_n = one_hot_dataframe(trainingset, ['City', 'Investors1', 'Investors2', 'Investors3', 'Investors4',\n",
      "                                                             'Founders1', 'Founders2', 'Founders3', 'Founders4',\n",
      "                                                             'Market1', 'Market2', 'Market3', 'Market4', \n",
      "                                                             'Market5'], replace=True)\n",
      "trainingset = trainingset.fillna(0)\n",
      "\n",
      "testset, testset_n = one_hot_dataframe(testset, ['Fate'], replace=True)\n",
      "testset = testset.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(trainingset, \n",
      "                                                                     testset, \n",
      "                                                                     test_size=0.4, \n",
      "                                                                     random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=30)\n",
      "clf = clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.73333333333333328"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_classification\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "importances = clf.feature_importances_\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. %s (%f)\" % (f + 1, trainingset.columns[indices][f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "figure(figsize=[10,6])\n",
      "barh(range(10), importances[indices][:10], color=\"orange\", align=\"center\")\n",
      "yticks(range(10), trainingset.columns[indices][:10])\n",
      "plt.ylim([-1,10])\n",
      "plt.gca().invert_yaxis()\n",
      "title(\"Feature Importances\")\n",
      "savefig('featureimportances.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Save the model \n",
      "# import pickle\n",
      "# pickle.dump( clf, open( \"randomforeststartup.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Going to clean up the fullset of data to run in random tree classifier.\n",
      "fullsetbackup = fullset\n",
      "fullsetbackup = fullsetbackup.drop(['Company','Title','TopComment','Fate','Description','Logo','SeedDBMattermarkProfile', \n",
      "                              'CrunchBaseAngelListProfile', 'Website', 'YCYear', 'YCSession'], 1)\n",
      "fullsetbackup[['Sentiment','TotalFunds']] = fullsetbackup[['Sentiment','TotalFunds']].fillna(0.0).astype(int)\n",
      "fullsetbackup, fullsetbackup_n = one_hot_dataframe(fullsetbackup, ['City', 'Investors1', 'Investors2', \n",
      "                                                                   'Investors3', 'Investors4', 'Founders1', 'Founders2', \n",
      "                                                                   'Founders3', 'Founders4','Market1', 'Market2', 'Market3', \n",
      "                                                                   'Market4', 'Market5'], replace=True)\n",
      "fullsetbackup = fullsetbackup.fillna(0)\n",
      "fullsetbackup = fullsetbackup[trainingset.columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = []\n",
      "probs = []\n",
      "for index, row in fullsetbackup.iterrows():\n",
      "    predictedfate = clf.predict(row)\n",
      "    probs.append(clf.predict_proba(row))\n",
      "    if predictedfate[0][0] > 0:\n",
      "        classifier.append('Dead')\n",
      "    else:\n",
      "        classifier.append('Operating')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probs[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[array([[ 0.86666667,  0.13333333]]), array([[ 0.13333333,  0.86666667]])]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fullset['PredictedClass'] = classifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Model validation\n",
      "scores = []\n",
      "ntrees = []\n",
      "for n in range(1,31):\n",
      "    clf_validation = RandomForestClassifier(n_estimators=n)\n",
      "    clf_validation = clf_validation.fit(X_train, y_train)\n",
      "    ntrees.append(n)\n",
      "    scores.append(clf_validation.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the mean accuracy of each random forest simulation.\n",
      "figure(figsize=[10,6])\n",
      "plot(ntrees, scores, color=\"orange\", linewidth=10)\n",
      "plt.ylim([0,1])\n",
      "plt.xlim([0,31])\n",
      "title('Test Accuracy')\n",
      "xlabel('Number of Trees')\n",
      "ylabel('Mean Accuracy Score')\n",
      "savefig('accuracytest.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Going to compute overall cross validation score across entire dataset to see how the model performs.\n",
      "fullsettarget = pd.DataFrame(fullset.Fate)\n",
      "fullsettarget, fullsettarget_n = one_hot_dataframe(fullsettarget, ['Fate'], replace=True)\n",
      "fullsettarget = fullsettarget.fillna(0)\n",
      "\n",
      "cvscores = cross_validation.cross_val_score(clf, X_test, y_test, cv=5)\n",
      "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (cvscores.mean(), cvscores.std() * 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.72 (+/- 0.13)\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances[indices][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotdata = pd.DataFrame(columns=['nTrees','Scores'])\n",
      "# plotdata.nTrees = ntrees\n",
      "# plotdata.Scores = scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# chartdata = pd.DataFrame(columns=['Features','FeatureValues'])\n",
      "# chartdata.Features = trainingset.columns[indices][:10]\n",
      "# chartdata.FeatureValues = importances[indices][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotdata.to_csv('PlotData.csv', sep=',', encoding='utf-8')\n",
      "# chartdata.to_csv('ChartData.csv', sep=',', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pickle\n",
      "# clf = pickle.load( open( \"randomforeststartup.p\", \"rb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Backing up fullset, now with predicted classifier.\n",
      "fullset.to_csv('FullSet.csv', sep=',', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}