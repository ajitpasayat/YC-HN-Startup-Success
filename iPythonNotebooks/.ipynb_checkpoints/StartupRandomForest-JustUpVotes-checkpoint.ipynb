{
 "metadata": {
  "name": "",
  "signature": "sha256:95bcec4f589531762143bf117b516670226627925953b3db338c780def17690d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import feature_extraction\n",
      "\n",
      "# Borrowed from: http://nbviewer.ipython.org/github/gmonce/scikit-learn-book/tree/master/ (Chapter 4)\n",
      "def one_hot_dataframe(data, cols, replace=False):\n",
      "    \"\"\" Takes a dataframe and a list of columns that need to be encoded.\n",
      "    Returns a 3-tuple comprising the data, the vectorized data,\n",
      "    and the fitted vectorizor.\n",
      "    Modified from https://gist.github.com/kljensen/5452382\n",
      "    \"\"\"\n",
      "    vec = feature_extraction.DictVectorizer()\n",
      "    mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
      "\n",
      "    vecData = pd.DataFrame(vec.fit_transform(data[cols].to_dict(outtype='records')).toarray())\n",
      "    vecData.columns = vec.get_feature_names()\n",
      "    vecData.index = data.index\n",
      "    if replace is True:\n",
      "        data = data.drop(cols, axis=1)\n",
      "        data = data.join(vecData)\n",
      "    return (data, vecData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load HackerNews data.\n",
      "hacerknewsdata = pd.DataFrame()\n",
      "hackernewsdata = pd.read_csv('../Datasets/HNTitleCommentsSentimentData.csv')\n",
      "hackernewsdata = hackernewsdata.drop(['Unnamed: 0'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load YC startups data.\n",
      "cleanstartups = pd.DataFrame()\n",
      "cleanstartups = pd.read_csv('../Datasets/CleanStartupsFull.csv')\n",
      "cleanstartups = cleanstartups.drop(['Unnamed: 0'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Merge the cleaned-up YC startup data with Hacker News data.\n",
      "fullset = pd.merge(hackernewsdata, cleanstartups, on='Company', how='inner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Going to convert those that have exited YC as remaining in operation.\n",
      "# I want to keep the perdiction simple: in operation or dead.\n",
      "# I will think of ways to incorporate startups that have exited as a classifer after my demo.\n",
      "fullset.Fate[fullset.Fate != 'Dead'] = 'Operating'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To create training set, first separate startups that are not operating versus those that remain in operation.\n",
      "# Because there aren't as many dead startups, I will only use an equal amount of active startups (chosen by random). \n",
      "deadset = fullset[fullset.Fate == 'Dead']\n",
      "operatingset = fullset[fullset.Fate == 'Operating']\n",
      "rows = np.random.choice(operatingset.index.values, len(deadset))\n",
      "operatingset = operatingset.ix[rows]\n",
      "\n",
      "# Now merge together the dead and operating startups -- this will be the training set for now.\n",
      "trainingset = deadset.append(operatingset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Truncating full set to exclude features that aren't going to be in the decision tree.\n",
      "trainingset = trainingset.drop(['Company','Title','TopComment','TopCommentPoints','Fate','Description','Logo',\n",
      "                    'SeedDBMattermarkProfile','CrunchBaseAngelListProfile','Website',\n",
      "                    'YCYear','YCSession','Market','Founders','Investors','TitlePoints'], 1)\n",
      "\n",
      "# Also have to deal with missing values and data types.\n",
      "trainingset[['Sentiment','TotalFunds']] = trainingset[['Sentiment','TotalFunds']].fillna(0.0).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testset = pd.DataFrame(fullset.Fate[trainingset.index])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import label_binarize\n",
      "# Transforming lists of feature-value mappings to vectors.\n",
      "# This also transforms and encodes categorical integer features using a variation of one-hot scheme.\n",
      "trainingset, trainingset_n = one_hot_dataframe(trainingset, ['City', 'Investors1', 'Investors2', 'Investors3', 'Investors4',\n",
      "                                                             'Founders1', 'Founders2', 'Founders3', 'Founders4',\n",
      "                                                             'Market1', 'Market2', 'Market3', 'Market4', \n",
      "                                                             'Market5'], replace=True)\n",
      "trainingset = trainingset.fillna(0)\n",
      "\n",
      "testset, testset_n = one_hot_dataframe(testset, ['Fate'], replace=True)\n",
      "testset = testset.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Binarize the output\n",
      "testset = label_binarize(testset, classes=[0, 1])\n",
      "n_classes = testset.shape[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(trainingset, \n",
      "                                                                     testset, \n",
      "                                                                     test_size=0.4)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=30,\n",
      "                             criterion=\"entropy\", \n",
      "                             max_features=\"auto\",\n",
      "                             bootstrap=True, \n",
      "                             n_jobs=8, \n",
      "                             random_state=1)\n",
      "clf = clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preds = clf.predict_proba(X_test)[:][1]\n",
      "clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "0.7142857142857143"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "font = {'family' : 'Arial',\n",
      "        'size'   : 20}\n",
      "\n",
      "plt.rc('font', **font)\n",
      "\n",
      "fpr = dict()\n",
      "tpr = dict()\n",
      "roc_auc = dict()\n",
      "for i in range(2):\n",
      "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
      "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
      "    \n",
      "# Compute micro-average ROC curve and ROC area\n",
      "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), preds.ravel())\n",
      "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
      "\n",
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure(figsize=(10, 7.5), dpi=600)\n",
      "plt.plot(fpr[1], tpr[1], label='ROC Curve (area = %0.2f)' % roc_auc[1], linewidth=3)\n",
      "plt.plot([0, 1], [0, 1], 'k--', linewidth=3)\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver Operating Characteristic')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.savefig('Figures/ROCCurve.png')\n",
      "plt.show()\n",
      "\n",
      "# Plot ROC curve\n",
      "plt.figure(figsize=(10, 7.5), dpi=600)\n",
      "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
      "         label='Micro-Average ROC Curve', linewidth=3)\n",
      "for i in range(2):\n",
      "    if i == 0:\n",
      "        plt.plot(fpr[i], tpr[i], label='ROC Curve - Not Operating', linewidth=3)\n",
      "    else:\n",
      "        plt.plot(fpr[i], tpr[i], label='ROC Curve - Operating', linewidth=3)\n",
      "plt.plot([0, 1], [0, 1], 'k--', linewidth=3)\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver Operating Characteristic to Multi-Class')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.savefig('Figures/ROCCurveMultiClass.png')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle.dump( clf, open( \"Datasets/RandomForestStartup.p\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import make_classification\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "importances = clf.feature_importances_\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print(\"Feature ranking:\")\n",
      "\n",
      "for f in range(10):\n",
      "    print(\"%d. %s (%f)\" % (f + 1, trainingset.columns[indices][f], importances[indices[f]]))\n",
      "\n",
      "# Plot the feature importances of the forest\n",
      "figure(figsize=(10, 7.5), dpi=600)\n",
      "barh(range(10), importances[indices][:10], color=\"orange\", align=\"center\")\n",
      "yticks(range(10), trainingset.columns[indices][:10])\n",
      "plt.ylim([-1,10])\n",
      "plt.gca().invert_yaxis()\n",
      "title(\"Feature Importances\")\n",
      "plt.savefig('Figures/FeatureImportance.png')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Going to clean up the fullset of data to run in random tree classifier.\n",
      "fullsetbackup = fullset\n",
      "fullsetbackup = fullsetbackup.drop(['Company','Title','TopComment','Fate','Description','Logo','SeedDBMattermarkProfile', \n",
      "                              'CrunchBaseAngelListProfile', 'Website', 'YCYear', 'YCSession',\n",
      "                              'Market','Founders','Investors'], 1)\n",
      "fullsetbackup[['Sentiment','TotalFunds']] = fullsetbackup[['Sentiment','TotalFunds']].fillna(0.0).astype(int)\n",
      "fullsetbackup, fullsetbackup_n = one_hot_dataframe(fullsetbackup, ['City', 'Investors1', 'Investors2', \n",
      "                                                                   'Investors3', 'Investors4', 'Founders1', 'Founders2', \n",
      "                                                                   'Founders3', 'Founders4','Market1', 'Market2', 'Market3', \n",
      "                                                                   'Market4', 'Market5'], replace=True)\n",
      "fullsetbackup = fullsetbackup.fillna(0)\n",
      "fullsetbackup = fullsetbackup[trainingset.columns]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = []\n",
      "probs = []\n",
      "for index, row in fullsetbackup.iterrows():\n",
      "    predictedfate = clf.predict(row)\n",
      "    if predictedfate[0][0] > 0:\n",
      "        classifier.append('Not Operating')\n",
      "        probs.append(clf.predict_proba(row)[0][0][1])\n",
      "    else:\n",
      "        classifier.append('Operating')\n",
      "        probs.append(clf.predict_proba(row)[1][0][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fullset['Prediction'] = classifier\n",
      "fullset['Probability'] = probs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotdata = pd.DataFrame(columns=['nTrees','Scores'])\n",
      "# plotdata.nTrees = ntrees\n",
      "# plotdata.Scores = scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# chartdata = pd.DataFrame(columns=['Features','FeatureValues'])\n",
      "# chartdata.Features = trainingset.columns[indices][:10]\n",
      "# chartdata.FeatureValues = importances[indices][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotdata.to_csv('PlotData.csv', sep=',', encoding='utf-8')\n",
      "# chartdata.to_csv('ChartData.csv', sep=',', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pickle\n",
      "# clf = pickle.load( open( \"randomforeststartup.p\", \"rb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Backing up fullset, now with predicted classifier.\n",
      "fullset.to_csv('Datasets/CompleteSet.csv', sep=',', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    }
   ],
   "metadata": {}
  }
 ]
}