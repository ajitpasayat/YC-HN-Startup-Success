{
 "metadata": {
  "name": "",
  "signature": "sha256:b5ab49a0e5fa3c217e0d03a72adf14d67eaa25e15ba1390c93be0cacfdbb8898"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import urllib2\n",
      "import json\n",
      "\n",
      "# Using the open-source Data Science Toolkit by Pete Warden for sentiment analysis.\n",
      "import dstk\n",
      "dstk = dstk.DSTK()\n",
      "\n",
      "# Parser used to decode HTML text.\n",
      "import HTMLParser\n",
      "h = HTMLParser.HTMLParser()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cleanstartups = pd.DataFrame()\n",
      "cleanstartups = pd.read_csv('CleanStartups.csv')\n",
      "cleanstartups = cleanstartups.drop(['Unnamed: 0'], 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hnstorycomment = pd.DataFrame(columns=('Company', 'Title', 'TitlePoints',\n",
      "                                    'TopComment', 'Sentiment', 'TopCommentPoints'))\n",
      "\n",
      "# For each startup, search for all stories that match based on when they participated in Y Combinator (season and year).\n",
      "for index, row in cleanstartups.iterrows():\n",
      "    \n",
      "    data = []\n",
      "    # API call to search for topics that feature a startups's YC announcement.\n",
      "    try:\n",
      "        url = 'https://hn.algolia.com/api/v1/search?query=%s+%s+%s%s&tags=story' % (cleanstartups.Company[index].replace(\" \", \"\"), \n",
      "                                                                                'YC', cleanstartups.YCSession[index][0],\n",
      "                                                                                str(cleanstartups.YCYear[0])[-2:])\n",
      "        req = urllib2.Request(url)\n",
      "        response = urllib2.urlopen(req)\n",
      "        data = json.loads(response.read())\n",
      "    except Exception, e:\n",
      "        print e\n",
      "            \n",
      "    # If no results were found, then try searching without the YC class session tag.\n",
      "    if not data or not data['hits']:\n",
      "        try:\n",
      "            url = 'https://hn.algolia.com/api/v1/search?query=%s&tags=story' % cleanstartups.Company[index].replace(\" \", \"\")\n",
      "            req = urllib2.Request(url)\n",
      "            response = urllib2.urlopen(req)\n",
      "            data = json.loads(response.read())\n",
      "        except Exception, e:\n",
      "            print e\n",
      "            \n",
      "        if not data or not data['hits']:\n",
      "            print row['Company'], url\n",
      "            continue\n",
      "            \n",
      "    topics = pd.DataFrame(data['hits'], columns=['title','points','objectID'])\n",
      "\n",
      "    # API call to retrieve comments of most upvoted story X, where X is the objectID retrieved from the previous API call.\n",
      "    try:\n",
      "        url = 'https://hn.algolia.com/api/v1/search?tags=comment,story_%s' % topics.loc[0,'objectID']\n",
      "        req = urllib2.Request(url)\n",
      "        response = urllib2.urlopen(req)\n",
      "    except Exception, e:\n",
      "        print e\n",
      "        \n",
      "    data = json.loads(response.read())\n",
      "    \n",
      "    if not data or not data['hits']:\n",
      "        print row['Company'], url\n",
      "        continue\n",
      "        \n",
      "    comments = pd.DataFrame(data['hits'], columns=['comment_text','points','created_at'])\n",
      "\n",
      "        \n",
      "    # API call to obtain sentiment value of top comment in most upvoted story.\n",
      "    topcomment = h.unescape(comments.loc[0,'comment_text']).encode('utf-8')\n",
      "    sentiment = dstk.text2sentiment(topcomment)['score']\n",
      "    \n",
      "    hnstorycomment.loc[index] = [row['Company'].encode('utf-8'), topics.loc[0,'title'].encode('utf-8'), topics.loc[0,'points'],\n",
      "                                 topcomment, sentiment, comments.loc[0,'points']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Export dataframe to CSV for backup.\n",
      "hnstorycomment.to_csv('HNTitleCommentsSentimentData.csv', sep=',', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}